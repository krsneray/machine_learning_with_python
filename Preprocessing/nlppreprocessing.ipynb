{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17fabed5-9eaf-4aa0-ab90-90f2666da6ce",
   "metadata": {},
   "source": [
    "## Gerekli Kütüphaneler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94797ff5-9c08-4439-b842-9aca6ad3fac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a25a7c-1d8b-485f-ada2-e1478be308fa",
   "metadata": {},
   "source": [
    "## Veri Setinin Eklenmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fa191ef-f4ec-4b09-b3db-e24fcf12c8d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 700 entries, 0 to 699\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Review  700 non-null    object \n",
      " 1   Liked   700 non-null    float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 11.1+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>If she had not rolled the eyes we may have sta...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Horrible - don't waste your time and money.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>Now this dish was quite flavourful.</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>By this time our side of the restaurant was al...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>-Drinks took close to 30 minutes to come out a...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  Liked\n",
       "0                             Wow... Loved this place.    1.0\n",
       "1                                   Crust is not good.    0.0\n",
       "2            Not tasty and the texture was just nasty.    0.0\n",
       "3    Stopped by during the late May bank holiday of...    1.0\n",
       "4    The selection on the menu was great and so wer...    1.0\n",
       "..                                                 ...    ...\n",
       "162  If she had not rolled the eyes we may have sta...    0.0\n",
       "163        Horrible - don't waste your time and money.    0.0\n",
       "164                Now this dish was quite flavourful.    1.0\n",
       "165  By this time our side of the restaurant was al...    0.0\n",
       "166  -Drinks took close to 30 minutes to come out a...    0.0\n",
       "\n",
       "[167 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Restaurant_Reviews_Cleaned.csv')\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "print(df.info())\n",
    "df.head(167)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0135ea-b70b-4486-a5e7-5853d6949fd6",
   "metadata": {},
   "source": [
    "## Veri Ön İşleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27c3c50b-1827-46ee-ac25-d203c4c85aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Veri setindeki noktalama işaretleri metni işleme açısından sıkıntı yaratıyor.\n",
    "#Çünkü play kelimesiyle play... aynı şeye hitap etse de makine bunu aynı kelime olarak algılamıyor.\n",
    "#Bu sebeple metinlerdeki noktalama işaretlerini çıkarmamız gerekiyor.\n",
    "#Aynı zamanda metindeki Play ile play aynı anlama gelmesine rağmen makine aynı olarak değerlendiremeyeceği için bütün harfleri küçültmemiz gerekiyor.\n",
    "#İngilizcede that did gibi (bu operasyon için) kelimeler gereksiz olacağından stopwords kullanarak metinden atıyoruz.\n",
    "#ps.steam kullanarak kelimelerin sadece gövdesini alıyoruz. (played --> play) gibi..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca16c581-e772-4183-8c1f-fca5e67304b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Kirsa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import re #Regular Expression\n",
    "\n",
    "import nltk #Natural Language Toolkit\n",
    "stopWords = nltk.download('stopwords')\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "derlem = []\n",
    "for i in range(700):\n",
    "    satir = re.sub('[^a-zA-Z]',' ',df['Review'][i])\n",
    "    satir = satir.lower()\n",
    "    satir = satir.split()\n",
    "    satir = [ps.stem(kelime) for kelime in satir if not kelime in set(stopwords.words('english'))]\n",
    "    satir = ' '.join(satir)\n",
    "    derlem.append(satir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f774987b-a25c-4271-9dd3-b8c4c11f9d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer #Feature Extraction (Öznitelik Çıkarımı)\n",
    "cv = CountVectorizer(max_features=2000)\n",
    "x = cv.fit_transform(derlem).toarray()\n",
    "y = df.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "853c3fd3-56d7-42e6-ab1b-dbaac792837f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x,y,test_size=0.20,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38523e3-030d-451d-a3dd-795f95681ac1",
   "metadata": {},
   "source": [
    "## Modelin Oluşturulması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6520eae1-ab23-4baf-ab40-78005eb59b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(xtrain,ytrain)\n",
    "ypred = gnb.predict(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554c57c5-2fa2-4ff3-8492-ffa7bc867e01",
   "metadata": {},
   "source": [
    "## Model Değerlendirmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "873cff26-2dcc-41ae-9b4b-887b10e1fc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38 30]\n",
      " [10 62]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(ytest,ypred)\n",
    "print(cm) #140 veriden 100'ü doğru %71.40 Accuracy oranı var."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
